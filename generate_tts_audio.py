"""
Gemini Live APIë¥¼ ì‚¬ìš©í•œ TTS ì˜¤ë””ì˜¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

Day 2 Listening í˜ì´ì§€ìš© ìŠ¤í† ë¦¬ ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ì‚¬ìš©ë²•
python generate_tts_audio.py

## í•„ìš” íŒ¨í‚¤ì§€
pip install google-genai pyaudio

## í™˜ê²½ ë³€ìˆ˜
export GEMINI_API_KEY="your_api_key"
"""

import os
import asyncio
import wave
import subprocess
from pathlib import Path

from google import genai
from google.genai import types

# ì˜¤ë””ì˜¤ ì„¤ì •
RECEIVE_SAMPLE_RATE = 24000
CHANNELS = 1
SAMPLE_WIDTH = 2  # 16-bit audio = 2 bytes

# ëª¨ë¸ ì„¤ì •
MODEL = "models/gemini-2.5-flash-native-audio-preview-12-2025"

# API í´ë¼ì´ì–¸íŠ¸
client = genai.Client(
    http_options={"api_version": "v1beta"},
    api_key=os.environ.get("GEMINI_API_KEY"),
)

# Live API ì„¤ì •
CONFIG = types.LiveConnectConfig(
    response_modalities=["AUDIO"],
    speech_config=types.SpeechConfig(
        voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(voice_name="Zephyr")
        )
    ),
)

# Day 1/Day 2 ìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸
STORY_TEXT = """
Hello! My name is James. I am 32 years old. I am a software engineer. I work at a tech company in Seoul.

I am from the United States, but I live in Korea now. I am married. My wife's name is Yuna. She is Korean. She is a teacher at an elementary school.

We have one daughter. Her name is Sophie. She is 5 years old. She is very cute and energetic.

My family is small but happy. I love my life in Seoul!
"""

# Day 4 Shadowing ë¬¸ì¥ë“¤ (ê°œë³„ ë¬¸ì¥, ì•½ê°„ì˜ ê°„ê²©ì„ ë‘ê³  ì²œì²œíˆ)
SHADOWING_SENTENCES = [
    "Hello! My name is James.",
    "I am 32 years old.",
    "I am a software engineer.",
    "I work at a tech company in Seoul.",
    "I am married.",
    "My wife's name is Yuna.",
    "She is a teacher.",
    "We have one daughter.",
    "My family is small but happy.",
    "I love my life in Seoul!"
]


async def generate_audio(text: str, output_path: str):
    """í…ìŠ¤íŠ¸ë¥¼ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥"""
    print(f"ğŸ¤ ì˜¤ë””ì˜¤ ìƒì„± ì¤‘: {output_path}")
    
    audio_chunks = []
    
    async with client.aio.live.connect(model=MODEL, config=CONFIG) as session:
        # í…ìŠ¤íŠ¸ ì „ì†¡ - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” í†¤ìœ¼ë¡œ
        await session.send(
            input=f"Read this text naturally in a warm, conversational tone. Speak as if you're a friendly American man casually introducing himself to a new friend. Use natural rhythm, linking between words, and authentic emotion: {text}",
            end_of_turn=True
        )
        
        # ì˜¤ë””ì˜¤ ì‘ë‹µ ìˆ˜ì‹ 
        turn = session.receive()
        async for response in turn:
            if data := response.data:
                audio_chunks.append(data)
            if text := response.text:
                print(f"  (í…ìŠ¤íŠ¸ ì‘ë‹µ: {text[:50]}...)" if len(text) > 50 else f"  (í…ìŠ¤íŠ¸ ì‘ë‹µ: {text})")
    
    if not audio_chunks:
        print("âŒ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return False
    
    # PCM ë°ì´í„° ê²°í•©
    pcm_data = b"".join(audio_chunks)
    
    # WAV íŒŒì¼ë¡œ ì €ì¥
    wav_path = output_path.replace(".mp3", ".wav")
    with wave.open(wav_path, "wb") as wav_file:
        wav_file.setnchannels(CHANNELS)
        wav_file.setsampwidth(SAMPLE_WIDTH)
        wav_file.setframerate(RECEIVE_SAMPLE_RATE)
        wav_file.writeframes(pcm_data)
    
    print(f"  âœ… WAV ì €ì¥ ì™„ë£Œ: {wav_path}")
    
    # MP3ë¡œ ë³€í™˜ (ffmpeg ì‚¬ìš©)
    try:
        subprocess.run([
            "ffmpeg", "-y", "-i", wav_path,
            "-codec:a", "libmp3lame", "-qscale:a", "2",
            output_path
        ], check=True, capture_output=True)
        print(f"  âœ… MP3 ë³€í™˜ ì™„ë£Œ: {output_path}")
        
        # WAV íŒŒì¼ ì‚­ì œ
        os.remove(wav_path)
        return True
    except subprocess.CalledProcessError as e:
        print(f"  âš ï¸ MP3 ë³€í™˜ ì‹¤íŒ¨. WAV íŒŒì¼ ìœ ì§€: {wav_path}")
        print(f"     ffmpeg ì˜¤ë¥˜: {e.stderr.decode()}")
        return True  # WAVëŠ” ì„±ê³µí–ˆìœ¼ë¯€ë¡œ True
    except FileNotFoundError:
        print("  âš ï¸ ffmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. WAV íŒŒì¼ ìœ ì§€.")
        return True


async def main():
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = Path("docs/assets/audio")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 50)
    print("ğŸ¤ Day 4 Shadowing ì˜¤ë””ì˜¤ ìƒì„±")
    print("=" * 50)
    
    # Shadowing ë¬¸ì¥ë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸° (ë¬¸ì¥ ì‚¬ì´ì— ì‰¼í‘œë¡œ êµ¬ë¶„)
    # ê° ë¬¸ì¥ í›„ ì•½ê°„ì˜ ë©ˆì¶¤ì„ ìœ„í•´ ì¤„ë°”ê¿ˆ ì¶”ê°€
    shadowing_text = "\n\n".join(SHADOWING_SENTENCES)
    
    output_file = output_dir / "week1_day4_shadowing.mp3"
    success = await generate_audio(shadowing_text, str(output_file))
    
    if success:
        print("\n" + "=" * 50)
        print("âœ… ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {output_file}")
        print("=" * 50)
    else:
        print("\nâŒ ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")


if __name__ == "__main__":
    asyncio.run(main())
